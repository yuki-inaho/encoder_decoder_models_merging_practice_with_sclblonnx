{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# エンコーダーモデルの定義\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(16 * 14 * 14, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output1 = self.fc1(x)\n",
    "        output2 = self.fc2(x)\n",
    "        return output1, output2\n",
    "\n",
    "\n",
    "# デコーダーモデル1の定義\n",
    "class Decoder1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder1, self).__init__()\n",
    "        self.fc = nn.Linear(192, 10)  # 128 + 64 = 192\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# デコーダーモデル2の定義\n",
    "class Decoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder2, self).__init__()\n",
    "        self.fc1 = nn.Linear(192, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder1 = Decoder1()\n",
    "decoder2 = Decoder2()\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "dummy_output1, dummy_output2 = encoder(dummy_input)\n",
    "\n",
    "torch.onnx.export(\n",
    "    encoder, dummy_input, \"encoder.onnx\", input_names=[\"input\"], output_names=[\"encoder_output1\", \"encoder_output2\"]\n",
    ")\n",
    "torch.onnx.export(\n",
    "    decoder1,\n",
    "    (dummy_output1, dummy_output2),\n",
    "    \"decoder1.onnx\",\n",
    "    input_names=[\"encoder_output1\", \"encoder_output2\"],\n",
    "    output_names=[\"output_dec1\"],\n",
    ")\n",
    "torch.onnx.export(\n",
    "    decoder2,\n",
    "    (dummy_output1, dummy_output2),\n",
    "    \"decoder2.onnx\",\n",
    "    input_names=[\"encoder_output1\", \"encoder_output2\"],\n",
    "    output_names=[\"output_dec2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sclblonnx as so\n",
    "\n",
    "# エンコーダーとデコーダーのONNXモデルを読み込む\n",
    "encoder_model = so.graph_from_file(\"encoder.onnx\")\n",
    "decoder_model_1 = so.graph_from_file(\"decoder1.onnx\")\n",
    "decoder_model_2 = so.graph_from_file(\"decoder2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プレフィックスを追加\n",
    "\n",
    "\n",
    "def add_prefix_to_nodes(graph, prefix, exclude_names):\n",
    "    def add_prefix(name):\n",
    "        if name in exclude_names:\n",
    "            return name\n",
    "        if name.startswith(\"/\"):\n",
    "            return f\"/{prefix}{name}\"\n",
    "        else:\n",
    "            return f\"/{prefix}/{name}\"\n",
    "\n",
    "    for node in graph.node:\n",
    "        node.name = add_prefix(node.name)\n",
    "        node.input[:] = [add_prefix(inp) for inp in node.input]\n",
    "        node.output[:] = [add_prefix(out) for out in node.output]\n",
    "    for init in graph.initializer:\n",
    "        init.name = add_prefix(init.name)\n",
    "    for input in graph.input:\n",
    "        input.name = add_prefix(input.name)\n",
    "    for output in graph.output:\n",
    "        output.name = add_prefix(output.name)\n",
    "    return graph\n",
    "\n",
    "\n",
    "# エンコーダーモデルの入力と出力の名前を取得\n",
    "encoder_inputs_outputs = [input.name for input in encoder_model.input] + [\n",
    "    output.name for output in encoder_model.output\n",
    "]\n",
    "\n",
    "# プレフィックスを追加\n",
    "decoder_model_1 = add_prefix_to_nodes(decoder_model_1, \"decoder1\", encoder_inputs_outputs)\n",
    "decoder_model_2 = add_prefix_to_nodes(decoder_model_2, \"decoder2\", encoder_inputs_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デコーダーの入力をエンコーダーの出力に接続\n",
    "encoder_output1 = encoder_model.output[0].name\n",
    "encoder_output2 = encoder_model.output[1].name\n",
    "decoder_model_1_input1 = decoder_model_1.input[0].name\n",
    "decoder_model_1_input2 = decoder_model_1.input[1].name\n",
    "decoder_model_2_input1 = decoder_model_2.input[0].name\n",
    "decoder_model_2_input2 = decoder_model_2.input[1].name\n",
    "\n",
    "decoder_model_1 = so.rename_input(decoder_model_1, decoder_model_1_input1, encoder_output1)\n",
    "decoder_model_1 = so.rename_input(decoder_model_1, decoder_model_1_input2, encoder_output2)\n",
    "decoder_model_2 = so.rename_input(decoder_model_2, decoder_model_2_input1, encoder_output1)\n",
    "decoder_model_2 = so.rename_input(decoder_model_2, decoder_model_2_input2, encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming node names in graph.\n",
      "Matching specified inputs and outputs..\n",
      "Pasting graphs.\n",
      "Running Scailable specific checks for WASM conversion. \n",
      "Use _sclbl_check=False to turn off\n",
      "Your graph was successfully checked.\n",
      "Renaming node names in graph.\n",
      "Matching specified inputs and outputs..\n",
      "Pasting graphs.\n",
      "Running Scailable specific checks for WASM conversion. \n",
      "Use _sclbl_check=False to turn off\n",
      "Your graph was successfully checked.\n",
      "Encoder and Decoders have been successfully merged into a single ONNX model.\n"
     ]
    }
   ],
   "source": [
    "# 全てのモデルを結合\n",
    "combined_model = so.merge(encoder_model, decoder_model_1, io_match=[(encoder_output1, encoder_output1), (encoder_output2, encoder_output2)])\n",
    "combined_model = so.merge(combined_model, decoder_model_2, io_match=[(encoder_output1, encoder_output1), (encoder_output2, encoder_output2)])\n",
    "\n",
    "# 結合ONNXモデルを保存\n",
    "so.graph_to_file(combined_model, \"combined_model.onnx\")\n",
    "print(\"Encoder and Decoders have been successfully merged into a single ONNX model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder and Decoders have been successfully merged into a single ONNX model.\n"
     ]
    }
   ],
   "source": [
    "# 結合ONNXモデルを保存\n",
    "so.graph_to_file(combined_model, \"combined_model.onnx\")\n",
    "print(\"Encoder and Decoders have been successfully merged into a single ONNX model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without sclblonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output node information before merging:\n",
      "Node name: /fc1/Gemm\n",
      "Node op type: Gemm\n",
      "Node inputs: ['/Reshape_output_0', 'fc1.weight', 'fc1.bias']\n",
      "Node outputs: ['encoder_output1']\n",
      "\n",
      "Node name: /fc2/Gemm\n",
      "Node op type: Gemm\n",
      "Node inputs: ['/Reshape_output_0', 'fc2.weight', 'fc2.bias']\n",
      "Node outputs: ['encoder_output2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxsim\n",
    "import onnx.helper as helper\n",
    "import onnx.compose as compose\n",
    "\n",
    "\n",
    "def print_output_node_info(model, output_names):\n",
    "    for node in model.graph.node:\n",
    "        for output in node.output:\n",
    "            if output in output_names:\n",
    "                print(f\"Node name: {node.name}\")\n",
    "                print(f\"Node op type: {node.op_type}\")\n",
    "                print(f\"Node inputs: {node.input}\")\n",
    "                print(f\"Node outputs: {node.output}\")\n",
    "                print()\n",
    "\n",
    "\n",
    "# Identityノードを追加する関数\n",
    "def add_identity_nodes(combined_model, output_names, prefix=\"\"):\n",
    "    for output_name in output_names:\n",
    "        identity_node = helper.make_node(\n",
    "            \"Identity\", [output_name], [output_name + f\"_{prefix}\"], name=output_name + \"_Identity\"\n",
    "        )\n",
    "        combined_model.graph.node.append(identity_node)\n",
    "        combined_model.graph.output.append(\n",
    "            helper.make_tensor_value_info(output_name + f\"_{prefix}\", onnx.TensorProto.FLOAT, None)\n",
    "        )\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "# ONNXモデルの読み込み\n",
    "encoder_model = onnx.load(\"encoder.onnx\")\n",
    "decoder_models = [onnx.load(\"decoder1.onnx\"), onnx.load(\"decoder2.onnx\")]\n",
    "\n",
    "\n",
    "# プレフィックスを追加\n",
    "decoder_prefixes = [\"decoder1@\", \"decoder2@\"]\n",
    "for i, decoder_model in enumerate(decoder_models):\n",
    "    decoder_models[i] = compose.add_prefix(decoder_model, prefix=decoder_prefixes[i])\n",
    "\n",
    "\n",
    "# エンコーダーモデルの出力ノード情報を取得\n",
    "encoder_output_names = [output.name for output in encoder_model.graph.output]\n",
    "print(\"Encoder output node information before merging:\")\n",
    "print_output_node_info(encoder_model, encoder_output_names)\n",
    "\n",
    "\n",
    "# 1番目のデコーダーモデルを結合\n",
    "index = 0\n",
    "io_map = [(output_name, decoder_prefixes[index] + output_name) for output_name in encoder_output_names]\n",
    "combined_model = compose.merge_models(encoder_model, decoder_models[index], io_map=io_map)\n",
    "\n",
    "# ノードにIdentityノードを追加\n",
    "combined_model = add_identity_nodes(combined_model, encoder_output_names, prefix=f\"{index + 2}\")\n",
    "\n",
    "# 2番目のデコーダーモデルを結合\n",
    "index = 1\n",
    "io_map = [\n",
    "    (output_name + f\"_{index + 1}\", decoder_prefixes[index] + output_name) for output_name in encoder_output_names\n",
    "]\n",
    "combined_model = compose.merge_models(combined_model, decoder_models[index], io_map=io_map)\n",
    "\n",
    "combined_sim_model, check_ok = onnxsim.simplify(combined_model)\n",
    "assert check_ok\n",
    "\n",
    "onnx.save(combined_sim_model, \"combined_model2.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encoder-decoder-model-merging-practice-wit-_GDpwi3C-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
